{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOz9SIAbgK17RRIoFpEIn/N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aziz122596/uzcosmos_1/blob/main/task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from transformers import TrainingArguments\n",
        "print(inspect.signature(TrainingArguments.__init__))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoftR-BZa2h2",
        "outputId": "90e616c5-93d2-419c-e6e1-a67a35e0e658"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(self, output_dir: Optional[str] = None, overwrite_output_dir: bool = False, do_train: bool = False, do_eval: bool = False, do_predict: bool = False, eval_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'no', prediction_loss_only: bool = False, per_device_train_batch_size: int = 8, per_device_eval_batch_size: int = 8, per_gpu_train_batch_size: Optional[int] = None, per_gpu_eval_batch_size: Optional[int] = None, gradient_accumulation_steps: int = 1, eval_accumulation_steps: Optional[int] = None, eval_delay: Optional[float] = 0, torch_empty_cache_steps: Optional[int] = None, learning_rate: float = 5e-05, weight_decay: float = 0.0, adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-08, max_grad_norm: float = 1.0, num_train_epochs: float = 3.0, max_steps: int = -1, lr_scheduler_type: Union[transformers.trainer_utils.SchedulerType, str] = 'linear', lr_scheduler_kwargs: Union[dict, str, NoneType] = <factory>, warmup_ratio: float = 0.0, warmup_steps: int = 0, log_level: Optional[str] = 'passive', log_level_replica: Optional[str] = 'warning', log_on_each_node: bool = True, logging_dir: Optional[str] = None, logging_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'steps', logging_first_step: bool = False, logging_steps: float = 500, logging_nan_inf_filter: bool = True, save_strategy: Union[transformers.trainer_utils.SaveStrategy, str] = 'steps', save_steps: float = 500, save_total_limit: Optional[int] = None, save_safetensors: Optional[bool] = True, save_on_each_node: bool = False, save_only_model: bool = False, restore_callback_states_from_checkpoint: bool = False, no_cuda: bool = False, use_cpu: bool = False, use_mps_device: bool = False, seed: int = 42, data_seed: Optional[int] = None, jit_mode_eval: bool = False, use_ipex: bool = False, bf16: bool = False, fp16: bool = False, fp16_opt_level: str = 'O1', half_precision_backend: str = 'auto', bf16_full_eval: bool = False, fp16_full_eval: bool = False, tf32: Optional[bool] = None, local_rank: int = -1, ddp_backend: Optional[str] = None, tpu_num_cores: Optional[int] = None, tpu_metrics_debug: bool = False, debug: Union[str, list[transformers.debug_utils.DebugOption]] = '', dataloader_drop_last: bool = False, eval_steps: Optional[float] = None, dataloader_num_workers: int = 0, dataloader_prefetch_factor: Optional[int] = None, past_index: int = -1, run_name: Optional[str] = None, disable_tqdm: Optional[bool] = None, remove_unused_columns: Optional[bool] = True, label_names: Optional[list[str]] = None, load_best_model_at_end: Optional[bool] = False, metric_for_best_model: Optional[str] = None, greater_is_better: Optional[bool] = None, ignore_data_skip: bool = False, fsdp: Union[list[transformers.trainer_utils.FSDPOption], str, NoneType] = '', fsdp_min_num_params: int = 0, fsdp_config: Union[dict, str, NoneType] = None, tp_size: Optional[int] = 0, fsdp_transformer_layer_cls_to_wrap: Optional[str] = None, accelerator_config: Union[dict, str, NoneType] = None, deepspeed: Union[dict, str, NoneType] = None, label_smoothing_factor: float = 0.0, optim: Union[transformers.training_args.OptimizerNames, str] = 'adamw_torch', optim_args: Optional[str] = None, adafactor: bool = False, group_by_length: bool = False, length_column_name: Optional[str] = 'length', report_to: Union[NoneType, str, list[str]] = None, ddp_find_unused_parameters: Optional[bool] = None, ddp_bucket_cap_mb: Optional[int] = None, ddp_broadcast_buffers: Optional[bool] = None, dataloader_pin_memory: bool = True, dataloader_persistent_workers: bool = False, skip_memory_metrics: bool = True, use_legacy_prediction_loop: bool = False, push_to_hub: bool = False, resume_from_checkpoint: Optional[str] = None, hub_model_id: Optional[str] = None, hub_strategy: Union[transformers.trainer_utils.HubStrategy, str] = 'every_save', hub_token: Optional[str] = None, hub_private_repo: Optional[bool] = None, hub_always_push: bool = False, gradient_checkpointing: bool = False, gradient_checkpointing_kwargs: Union[dict, str, NoneType] = None, include_inputs_for_metrics: bool = False, include_for_metrics: list[str] = <factory>, eval_do_concat_batches: bool = True, fp16_backend: str = 'auto', push_to_hub_model_id: Optional[str] = None, push_to_hub_organization: Optional[str] = None, push_to_hub_token: Optional[str] = None, mp_parameters: str = '', auto_find_batch_size: bool = False, full_determinism: bool = False, torchdynamo: Optional[str] = None, ray_scope: Optional[str] = 'last', ddp_timeout: Optional[int] = 1800, torch_compile: bool = False, torch_compile_backend: Optional[str] = None, torch_compile_mode: Optional[str] = None, include_tokens_per_second: Optional[bool] = False, include_num_input_tokens_seen: Optional[bool] = False, neftune_noise_alpha: Optional[float] = None, optim_target_modules: Union[NoneType, str, list[str]] = None, batch_eval_metrics: bool = False, eval_on_start: bool = False, use_liger_kernel: Optional[bool] = False, eval_use_gather_object: Optional[bool] = False, average_tokens_across_devices: Optional[bool] = False) -> None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall transformers\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA_qdrY-a4CF",
        "outputId": "6a418ece-db4a-458a-d526-0f44f5d57422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.51.3\n",
            "Uninstalling transformers-4.51.3:\n",
            "  Would remove:\n",
            "    /usr/local/bin/transformers-cli\n",
            "    /usr/local/lib/python3.11/dist-packages/transformers-4.51.3.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/transformers/*\n",
            "Proceed (Y/n)? "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch scikit-learn accelerate matplotlib seaborn pandas"
      ],
      "metadata": {
        "id": "e6IIqBqRcGNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2QDs1IsS42E"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "print(f\"--- Версия Transformers, ЗАГРУЖЕННАЯ в сессию: {transformers.__version__} ---\")\n",
        "\n",
        "import datasets\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import torch\n",
        "import os # Для создания папок\n",
        "\n",
        "print(\"\\n--- Шаг 1: Загрузка датасета SST-2 ---\")\n",
        "dataset = datasets.load_dataset(\"glue\", \"sst2\")\n",
        "print(dataset)\n",
        "\n",
        "print(\"\\n--- Шаг 2: Токенизация ---\")\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "print(f\"Загрузка токенизатора {MODEL_NAME}...\")\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "print(\"Токенизация данных...\")\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "print(\"Обработка датасета...\")\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "# Разделяем на обучающую и валидационную выборки\n",
        "train_dataset = tokenized_datasets[\"train\"]\n",
        "eval_dataset = tokenized_datasets[\"validation\"]\n",
        "print(\"Данные подготовлены.\")\n",
        "\n",
        "print(\"\\n--- Шаг 3: Загрузка модели ---\")\n",
        "print(f\"Загрузка модели {MODEL_NAME} для классификации последовательностей...\")\n",
        "num_labels=2 для бинарной классификации (positive/negative)\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Модель загружена и перемещена на устройство: {device}\")\n",
        "\n",
        "print(\"\\n--- Шаг 4: Функция для вычисления метрик ---\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='binary')\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "    }\n",
        "print(\"Функция compute_metrics определена.\")\n",
        "\n",
        "minimal_output_dir = './results_sst2_minimal_test'\n",
        "os.makedirs(minimal_output_dir, exist_ok=True) # Создаем папку\n",
        "print(f\"Проверка минимального вызова TrainingArguments(output_dir='{minimal_output_dir}')...\")\n",
        "minimal_args_ok = False\n",
        "try:\n",
        "    minimal_args = TrainingArguments(output_dir=minimal_output_dir)\n",
        "    print(\">>> Минимальный вызов TrainingArguments УСПЕШЕН.\")\n",
        "    minimal_args_ok = True\n",
        "except Exception as e:\n",
        "    print(f\">>> Минимальный вызов TrainingArguments НЕУДАЧЕН: {e}\")\n",
        "    print(\">>> Если этот минимальный вызов не работает, проблема серьезная.\")\n",
        "    print(\">>> Возможно, потребуется 'Сбросить настройки среды выполнения...'\")\n",
        "\n",
        "print(\"--- Конец диагностики ---\\n\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Шаг 5: Настройка аргументов обучения ---\")\n",
        "\n",
        "if minimal_args_ok:\n",
        "    try:\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir='./results_sst2',\n",
        "            num_train_epochs=3,\n",
        "            per_device_train_batch_size=16,\n",
        "            per_device_eval_batch_size=64,\n",
        "            warmup_steps=500,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir='./logs_sst2',\n",
        "            logging_strategy=\"steps\",\n",
        "            logging_steps=100,\n",
        "            eval_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"f1\",\n",
        "            report_to=\"tensorboard\",\n",
        "            save_total_limit=2,\n",
        "        )\n",
        "        print(\"Объект TrainingArguments успешно создан.\")\n",
        "\n",
        "        print(\"\\n--- Шаг 6: Создание объекта Trainer ---\")\n",
        "        trainer = Trainer(\n",
        "            model=model,                         # Модель\n",
        "            args=training_args,                  # Аргументы обучения\n",
        "            train_dataset=train_dataset,         # Обучающий датасет\n",
        "            eval_dataset=eval_dataset,           # Валидационный датасет\n",
        "            compute_metrics=compute_metrics,     # Функция метрик\n",
        "            tokenizer=tokenizer,                 # Токенизатор\n",
        "        )\n",
        "        print(\"Объект Trainer успешно создан.\")\n",
        "\n",
        "        print(\"\\n--- Шаг 7: Запуск обучения ---\")\n",
        "        torch.cuda.empty_cache()\n",
        "        train_result = trainer.train()\n",
        "        print(\"Обучение завершено.\")\n",
        "\n",
        "        #метрики обучения\n",
        "        metrics = train_result.metrics\n",
        "        trainer.log_metrics(\"train\", metrics)\n",
        "        trainer.save_metrics(\"train\", metrics)\n",
        "\n",
        "\n",
        "        print(\"\\n--- Шаг 8: Сохранение лучшей модели ---\")\n",
        "        best_model_path = './results_sst2/best_model'\n",
        "        print(f\"Сохранение лучшей модели (и токенизатора) в {best_model_path}...\")\n",
        "        trainer.save_model(best_model_path)\n",
        "        tokenizer.save_pretrained(best_model_path)\n",
        "        print(\"Лучшая модель и токенизатор сохранены.\")\n",
        "\n",
        "        print(\"\\n--- Шаг 9: Оценка лучшей модели ---\")\n",
        "        eval_metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
        "        print(f\"Метрики на валидационном наборе:\")\n",
        "        trainer.log_metrics(\"eval\", eval_metrics)\n",
        "        trainer.save_metrics(\"eval\", eval_metrics)\n",
        "\n",
        "\n",
        "print(\"\\n--- Выполнение скрипта завершено---\")"
      ]
    }
  ]
}